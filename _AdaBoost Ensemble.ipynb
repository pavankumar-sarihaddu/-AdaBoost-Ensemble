{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi, in this lesson, you will discover the adaptive boosting or AdaBoost ensemble.\n",
    "\n",
    "Boosting involves adding models sequentially to the ensemble where new models attempt to correct the errors made by prior models already added to the ensemble. As such, the more ensemble members that are added, the fewer errors the ensemble is expected to make, at least to a limit supported by the data and before overfitting the training dataset.\n",
    "\n",
    "The idea of boosting was first developed as a theoretical idea, and the AdaBoost algorithm was the first successful approach to realizing a boosting-based ensemble algorithm.\n",
    "\n",
    "AdaBoost works by fitting decision trees on versions of the training dataset weighted so that the tree pays more attention to examples (rows) that the prior members got wrong, and less attention to those that the prior models got correct.\n",
    "\n",
    "Rather than full decision trees, AdaBoost uses very simple trees that make a single decision on one input variable before making a prediction. These short trees are referred to as decision stumps.\n",
    "\n",
    "AdaBoost is available in scikit-learn via the AdaBoostClassifier and AdaBoostRegressor classes, which use a decision tree (decision stump) as the base-model by default and you can specify the number of trees to create via the n_estimators argument.\n",
    "\n",
    "The complete example of evaluating an AdaBoost ensemble for classification is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.947 (0.088)\n"
     ]
    }
   ],
   "source": [
    "# example of evaluating an AdaBoost ensemble for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# create the synthetic classification dataset\n",
    "X, y = make_classification(random_state=1)\n",
    "# configure the ensemble model\n",
    "model = AdaBoostClassifier(n_estimators=50)\n",
    "# configure the resampling method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the ensemble on the dataset using the resampling method\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report ensemble performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
